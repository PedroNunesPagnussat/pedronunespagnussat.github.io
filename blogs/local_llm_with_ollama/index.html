<!DOCTYPE html>
<html lang="en" class="dark">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>How to Run Local LLMs with Ollama - Pedro Nunes Pagnussat</title>
        
        
        <link rel="apple-touch-icon" sizes="180x180" href="https://pedronunespagnussat.github.io/favicon_io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://pedronunespagnussat.github.io/favicon_io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://pedronunespagnussat.github.io/favicon_io/favicon-16x16.png">
        <link rel="manifest" href="https://pedronunespagnussat.github.io/favicon_io/site.webmanifest">        
        <link rel="preload" href="https://cdn.tailwindcss.com" as="script">
        <link rel="preload" href="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/devicon.min.css" as="style">
        
        
        <style>
            html, body {
                background-color: #121212;
                color: #f3f4f6;
            }            
            .border {
                border-color: #374151;
            }            
            .carousel-item {
                display: inline-block;
                margin: 0 1rem;
            }            
            .flex {
                display: flex;
            }
            .flex-col {
                flex-direction: column;
            }
            
            @media (min-width: 768px) {
                .md\:flex-row {
                    flex-direction: row;
                }
            }
            
            .tech-carousel {
                overflow: hidden;
                width: 100%;
                padding: 1rem 0;
            }
            
            .carousel-track {
                white-space: nowrap;
            }
        </style>
        
        <script src="https://cdn.tailwindcss.com"></script>
        <link rel="stylesheet" type='text/css' href="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/devicon.min.css" />
        <script>
            
            if (localStorage.getItem('color-theme') === 'dark' || (!('color-theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
                document.documentElement.classList.add('dark');
            } else {
                document.documentElement.classList.remove('dark');
            }
        </script>
        <style>
            :root {
                color-scheme: dark;
            }
            
            body {
                @apply bg-[#121212] text-gray-100;
            }

            .tech-icon {
                filter: grayscale(100%) brightness(200%);
                transition: all 0.3s ease;
            }
            .tech-icon:hover {
                filter: none;
            }
            
            @keyframes scroll {
                0% {
                    transform: translateX(0);
                }
                100% {
                    transform: translateX(-100%);
                }
            }
            
            .tech-carousel {
                width: 100%;
                padding: 1rem 0;
            }
            
            .tech-track {
                width: fit-content;
                animation: scroll 20s linear infinite;
            }
            
            .tech-track:hover {
                animation-play-state: paused;
            }
            
            .tech-slide {
                float: left;
            }
        </style>
    </head>
    <body class="min-h-screen bg-[#121212] text-gray-100">
        
<head>
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C0RTF18BT4"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-C0RTF18BT4');
    </script>
    
    <link rel="stylesheet" type='text/css' href="https://cdn.jsdelivr.net/gh/devicons/devicon@latest/devicon.min.css" />
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <style>
        body {
            font-family: 'Space Grotesk', sans-serif;
        }
    </style>
</head>
<header class="py-6 relative">
    <div class="max-w-6xl mx-auto px-4">
        <div class="flex flex-col md:flex-row md:items-center md:justify-between gap-4">
            <div class="flex justify-between items-center">
                <a href="https://pedronunespagnussat.github.io/" class="text-xl font-bold text-white hover:text-gray-300 transition-colors duration-300">
                    Pedro Nunes Pagnussat
                </a>
                
                <button id="mobile-menu-button" class="md:hidden text-gray-300 hover:text-white focus:outline-none">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path>
                    </svg>
                </button>
            </div>            
            
            <nav class="hidden md:flex flex-wrap justify-center items-center gap-4 md:gap-6">
                
                <a href="https://pedronunespagnussat.github.io/about/" class="inline-block text-lg text-gray-300 hover:text-white transition-colors duration-300 ">About</a>
                
                <a href="https://pedronunespagnussat.github.io/experience/" class="inline-block text-lg text-gray-300 hover:text-white transition-colors duration-300 ">Experience</a>
                
                <a href="https://pedronunespagnussat.github.io/projects/" class="inline-block text-lg text-gray-300 hover:text-white transition-colors duration-300 ">Projects</a>
                
                <a href="https://pedronunespagnussat.github.io/blogs/" class="inline-block text-lg text-gray-300 hover:text-white transition-colors duration-300 ">Blogs</a>
                
                <a href="https://pedronunespagnussat.github.io/contact/" class="inline-block text-lg text-gray-300 hover:text-white transition-colors duration-300 ">Contact Me</a>
                
            </nav>
            <div class="hidden md:flex justify-end">
                <div class="flex items-center">
                    <span class="text-lg text-gray-300 mr-2">My Time:</span>
                    <div id="local-time" class="text-lg text-gray-300"></div>
                </div>
            </div>
        </div>
    </div>

    
    <div id="mobile-menu" class="fixed inset-0 bg-black bg-opacity-90 z-50 hidden transition-all duration-300">
        <div class="flex flex-col h-full">
            <div class="flex justify-between items-center p-6 border-b border-gray-800">
                <span class="text-xl font-bold text-white">Menu</span>
                <button id="mobile-menu-close" class="text-gray-300 hover:text-white focus:outline-none">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
                    </svg>
                </button>
            </div>
            <nav class="flex flex-col p-6 space-y-4">
                
                <a href="https://pedronunespagnussat.github.io/about/" class="text-xl text-gray-300 hover:text-white transition-colors duration-300 ">About</a>
                
                <a href="https://pedronunespagnussat.github.io/experience/" class="text-xl text-gray-300 hover:text-white transition-colors duration-300 ">Experience</a>
                
                <a href="https://pedronunespagnussat.github.io/projects/" class="text-xl text-gray-300 hover:text-white transition-colors duration-300 ">Projects</a>
                
                <a href="https://pedronunespagnussat.github.io/blogs/" class="text-xl text-gray-300 hover:text-white transition-colors duration-300 ">Blogs</a>
                
                <a href="https://pedronunespagnussat.github.io/contact/" class="text-xl text-gray-300 hover:text-white transition-colors duration-300 ">Contact Me</a>
                
            </nav>
            <div class="mt-auto p-6 border-t border-gray-800">
                <div class="flex items-center justify-center">
                    <span class="text-lg text-gray-300 mr-2">Local Time:</span>
                    <div id="mobile-local-time" class="text-lg text-gray-300"></div>
                </div>
            </div>
        </div>
    </div>
</header>

<script>
    
    function updateLocalTime() {
        const timeElements = document.querySelectorAll('#local-time, #mobile-local-time');
        timeElements.forEach(element => {
            if (element) {
                const now = new Date();
                const timeString = now.toLocaleTimeString('pt-BR', {
                    timeZone: 'America/Sao_Paulo',
                    hour: '2-digit',
                    minute: '2-digit',
                    hour12: false
                });
                element.textContent = timeString;
            }
        });
    }
    updateLocalTime();
    setInterval(updateLocalTime, 1000);

    
    const mobileMenuButton = document.getElementById('mobile-menu-button');
    const mobileMenuClose = document.getElementById('mobile-menu-close');
    const mobileMenu = document.getElementById('mobile-menu');

    function toggleMobileMenu() {
        const isHidden = mobileMenu.classList.contains('hidden');
        if (isHidden) {
            mobileMenu.classList.remove('hidden');
            document.body.style.overflow = 'hidden'; 
        } else {
            mobileMenu.classList.add('hidden');
            document.body.style.overflow = ''; 
        }
    }

    mobileMenuButton.addEventListener('click', toggleMobileMenu);
    mobileMenuClose.addEventListener('click', toggleMobileMenu);

    
    const mobileMenuLinks = mobileMenu.querySelectorAll('a');
    mobileMenuLinks.forEach(link => {
        link.addEventListener('click', () => {
            toggleMobileMenu();
        });
    });

    
    const themeToggleBtn = document.getElementById('theme-toggle');
    if (themeToggleBtn) {
        const themeToggleDarkIcon = document.getElementById('theme-toggle-dark-icon');
        const themeToggleLightIcon = document.getElementById('theme-toggle-light-icon');

        if (localStorage.getItem('color-theme') === 'dark' || (!('color-theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
            themeToggleLightIcon.classList.remove('hidden');
            themeToggleDarkIcon.classList.add('hidden');
        } else {
            themeToggleLightIcon.classList.add('hidden');
            themeToggleDarkIcon.classList.remove('hidden');
        }

        themeToggleBtn.addEventListener('click', function() {
            themeToggleDarkIcon.classList.toggle('hidden');
            themeToggleLightIcon.classList.toggle('hidden');

            if (localStorage.getItem('color-theme')) {
                if (localStorage.getItem('color-theme') === 'light') {
                    document.documentElement.classList.add('dark');
                    localStorage.setItem('color-theme', 'dark');
                } else {
                    document.documentElement.classList.remove('dark');
                    localStorage.setItem('color-theme', 'light');
                }
            } else {
                if (document.documentElement.classList.contains('dark')) {
                    document.documentElement.classList.remove('dark');
                    localStorage.setItem('color-theme', 'light');
                } else {
                    document.documentElement.classList.add('dark');
                    localStorage.setItem('color-theme', 'dark');
                }
            }
        });
    }
</script> 
        <main>
            
<div class="w-full md:w-11/12 lg:w-10/12 xl:w-9/12 mx-auto py-8 md:py-12 px-4 md:px-6">
    <div class="max-w-6xl mx-auto p-4 md:p-8 border border-gray-800 rounded-2xl bg-[#121212]">
        <h1 class="text-4xl font-bold mb-4 text-white">How to Run Local LLMs with Ollama</h1>
        
            <div class="flex items-center gap-4 mb-8 text-gray-400">
                <time datetime="2025-03-31">March 31, 2025</time>
                <div class="flex flex-wrap gap-2">
                    
                    <span class="px-2 py-1 bg-gray-800 rounded-md text-xs font-medium text-gray-300">LLM</span>
                    
                    <span class="px-2 py-1 bg-gray-800 rounded-md text-xs font-medium text-gray-300">AI</span>
                    
                    <span class="px-2 py-1 bg-gray-800 rounded-md text-xs font-medium text-gray-300">Chat Bot</span>
                    
                </div>
            </div>
        
        
        <div class="prose prose-invert max-w-none">
            <style>
                 
                .prose h2 {
                    color: #fff;
                    font-size: 1.875rem;
                    margin-top: 2.5rem;
                    margin-bottom: 1.25rem;
                    font-weight: 700;
                    line-height: 1.3;
                }
                .prose h3 {
                    color: #fff;
                    font-size: 1.5rem;
                    margin-top: 2rem;
                    margin-bottom: 1rem;
                    font-weight: 600;
                }
                .prose p {
                    margin-top: 1.25rem;
                    margin-bottom: 1.25rem;
                }
                .prose ul {
                    margin-top: 1.25rem;
                    margin-bottom: 1.25rem;
                    list-style-type: disc;
                    padding-left: 1.625rem;
                }
                .prose li {
                    margin-top: 0.5rem;
                    margin-bottom: 0.5rem;
                }
                .prose code {
                    color: #e5e7eb;
                    background-color: #1f2937;
                    padding: 0.2rem 0.4rem;
                    border-radius: 0.25rem;
                    font-size: 0.875em;
                }
                .prose pre {
                    background-color: #1f2937;
                    padding: 1rem;
                    border-radius: 0.5rem;
                    overflow-x: auto;
                    margin: 1.5rem 0;
                }
                .prose pre code {
                    background-color: transparent;
                    padding: 0;
                    border-radius: 0;
                }
            </style>
            <p>Running local LLMs with Ollama is an exciting way to bring powerful AI models directly on your hardware, enhancing privacy, network dependancy, and reducing development costs.</p>
<h2 id="-why-run-local-llms">üöÄ Why Run Local LLMs?</h2>
<ul>
<li><strong>Privacy:</strong> Your data stays entirely on your local machine, crucial for sensitive information.</li>
<li><strong>Speed and Availability:</strong> No network latency or Availability problems</li>
<li><strong>Pricing:</strong> Enhancing privacy, reducing network dependency, and lowering development costs</li>
</ul>
<h2 id="-getting-started-with-ollama">üõ† Getting Started with Ollama</h2>
<h3 id="download">Download</h3>
<p><strong>Linux:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>curl -fsSL https://ollama.com/install.sh | sh
</span></span></code></pre></div><p><strong>Windows:</strong> Visit the <a href="https://ollama.com/download/windows">Ollama download page</a> and download the installer (<code>.exe</code>).
<strong>MacOS</strong> Visit the <a href="https://ollama.com/download/mac">Ollama download page</a> and download the installer (<code>.app</code>)</p>
<h3 id="pulling-models">Pulling Models</h3>
<p>To download a model:</p>
<pre tabindex="0"><code>ollama pull &lt;MODEL&gt;
</code></pre><p>Example with Llama2:</p>
<pre tabindex="0"><code>ollama pull llama2
</code></pre><h3 id="running-models">Running Models</h3>
<p>Run a model directly from your terminal:</p>
<pre tabindex="0"><code>ollama run &lt;MODEL&gt;
</code></pre><p>Example:</p>
<pre tabindex="0"><code>ollama run llama2
</code></pre><p>Interact with your model by typing prompts. To exit, simply type:</p>
<pre tabindex="0"><code>/bye
</code></pre><h3 id="saving-and-loading-chats">Saving and Loading chats</h3>
<p>Ollama provides simple commands to save and load chat histories. You can save a chat session directly from your terminal by running when in a chat:</p>
<pre tabindex="0"><code>/save chat-session-name
</code></pre><p>Later, load the saved session to continue your conversation:</p>
<pre tabindex="0"><code>/load chat-session-name
</code></pre><p>This makes it easy to pick up conversations right where you left off.</p>
<h2 id="-using-the-ollama-api">‚ú® Using the Ollama API</h2>
<p>Create a simple terminal-based chat application:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize chat history</span>
</span></span><span style="display:flex;"><span>messages <span style="color:#f92672">=</span> [{<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: <span style="color:#e6db74">&#34;You&#39;re my assistant named Jarvis. I&#39;m Tony&#34;</span>}]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        user_input <span style="color:#f92672">=</span> input(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">You: &#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">KeyboardInterrupt</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Goodbye!&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> user_input<span style="color:#f92672">.</span>lower() <span style="color:#f92672">in</span> [<span style="color:#e6db74">&#34;exit&#34;</span>, <span style="color:#e6db74">&#34;quit&#34;</span>]:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#34;Ending chat...&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Add user message to history</span>
</span></span><span style="display:flex;"><span>    messages<span style="color:#f92672">.</span>append({<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: user_input})
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Stream the assistant&#39;s response</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Jarvis: &#34;</span>, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> requests<span style="color:#f92672">.</span>post(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;http://localhost:11434/api/generate&#34;</span>,
</span></span><span style="display:flex;"><span>        json<span style="color:#f92672">=</span>{
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;model&#34;</span>: <span style="color:#e6db74">&#34;llama2&#34;</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;prompt&#34;</span>: <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>join([<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>m[<span style="color:#e6db74">&#39;role&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>m[<span style="color:#e6db74">&#39;content&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> messages]),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;stream&#34;</span>: <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        stream<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    ) <span style="color:#66d9ef">as</span> response:
</span></span><span style="display:flex;"><span>        response<span style="color:#f92672">.</span>raise_for_status()
</span></span><span style="display:flex;"><span>        full_response <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> response<span style="color:#f92672">.</span>iter_lines():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> line:
</span></span><span style="display:flex;"><span>                token <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>loads(line<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#34;utf-8&#34;</span>))
</span></span><span style="display:flex;"><span>                chunk <span style="color:#f92672">=</span> token<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;response&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> chunk:
</span></span><span style="display:flex;"><span>                    full_response <span style="color:#f92672">+=</span> chunk
</span></span><span style="display:flex;"><span>                    print(chunk, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> token<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;done&#34;</span>):
</span></span><span style="display:flex;"><span>                    <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Add assistant response to history</span>
</span></span><span style="display:flex;"><span>    messages<span style="color:#f92672">.</span>append({<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;assistant&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: full_response})
</span></span></code></pre></div><pre tabindex="0"><code>You: Hello Jarvis
Jarvis: Hello, Mr. Stark! *adjusts glasses* It&#39;s a pleasure to assist you as always. Is there something you need help with today?
You:   
</code></pre><h2 id="-using-ollama-python-package">üêç Using Ollama python package:</h2>
<p><strong>Note:</strong> Before running the Python script below, ensure you&rsquo;ve installed Ollama:</p>
<pre tabindex="0"><code>pip install ollama
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> ollama
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>MODEL_NAME <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;llama2&#34;</span>
</span></span><span style="display:flex;"><span>ollama<span style="color:#f92672">.</span>pull(MODEL_NAME)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>SYSTEM_PROMPT <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;You&#39;re my assistant named Jarvis. I&#39;m Tony&#34;</span>
</span></span><span style="display:flex;"><span>USER_PROMPT <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Hello, how are you?&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>messages <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: SYSTEM_PROMPT},
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: USER_PROMPT},
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Jarvis: &#34;</span>, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> ollama<span style="color:#f92672">.</span>chat(model<span style="color:#f92672">=</span>MODEL_NAME, messages<span style="color:#f92672">=</span>messages, stream<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print response chunks progressively</span>
</span></span><span style="display:flex;"><span>full_response <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> chunk <span style="color:#f92672">in</span> response:
</span></span><span style="display:flex;"><span>    content <span style="color:#f92672">=</span> chunk<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;message&#34;</span>, {})<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;content&#34;</span>, <span style="color:#e6db74">&#34;&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> content:
</span></span><span style="display:flex;"><span>        print(content, end<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&#34;</span>, flush<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        full_response<span style="color:#f92672">.</span>append(content)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)  <span style="color:#75715e"># Add final newlines</span>
</span></span></code></pre></div><p><strong>Example Output:</strong></p>
<pre tabindex="0"><code>Jarvis:
Ah, good day to you, sir! *adjusts monocle* I am functioning within normal parameters, thank you for inquiring. How may I assist you today? Is there something in particular you require, or perhaps a task you&#39;d like me to attend to? üòä
</code></pre><h2 id="-using-ollama-with-openai-compatibility">üîÅ Using Ollama with OpenAi Compatibility:</h2>
<p>To make ollama compatible with OpenAi format is very simple you juist need to initialize your clint using ollama</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>client <span style="color:#f92672">=</span> OpenAI(
</span></span><span style="display:flex;"><span>    base_url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;http://localhost:11434/v1&#39;</span>,
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;ollama&#39;</span>, <span style="color:#75715e"># required, but unused</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>response <span style="color:#f92672">=</span> client<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>  model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;llama2&#34;</span>,
</span></span><span style="display:flex;"><span>  messages<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: <span style="color:#e6db74">&#34;...&#34;</span>},
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: <span style="color:#e6db74">&#34;...&#34;</span>},
</span></span><span style="display:flex;"><span>    {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;assistant&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: <span style="color:#e6db74">&#34;...&#34;</span>},
</span></span><span style="display:flex;"><span>  ]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>response<span style="color:#f92672">.</span>choices[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>message<span style="color:#f92672">.</span>content
</span></span></code></pre></div><p>This can be usefull for checking you code workflow and OpenAI calls without charges</p>
<h2 id="-advanced-use-combine-local-and-cloud-models">üß† Advanced Use: Combine Local and Cloud Models</h2>
<p>You can leverage advanced reasoning models like DeepSeek to perform complex tasks and even orchestrate calls to more powerful external models, such as GPT-4. This approach allows combining the speed and privacy of local models with the advanced capabilities of external APIs.</p>
<p>Pull a reasoning model with:</p>
<pre tabindex="0"><code>ollama pull deepseek-r1:7b
</code></pre><p>Here&rsquo;s an example demonstrating how to use DeepSeek locally to make API calls to GPT-4 for tasks that require advanced reasoning:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> ollama
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> openai
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get initial response from local model</span>
</span></span><span style="display:flex;"><span>ollama<span style="color:#f92672">.</span>pull(<span style="color:#e6db74">&#34;deepseek-r1:7b&#34;</span>)
</span></span><span style="display:flex;"><span>reasoning_response <span style="color:#f92672">=</span> ollama<span style="color:#f92672">.</span>generate(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;deepseek-r1:7b&#34;</span>,
</span></span><span style="display:flex;"><span>    prompt<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Analyze and explain the core reasoning steps for: [Your Complex Issue Here]&#34;</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>reasoning_response <span style="color:#f92672">=</span> reasoning_response[<span style="color:#e6db74">&#34;response&#34;</span>]<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;&lt;/think&gt;&#34;</span>)[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>strip()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>api_response <span style="color:#f92672">=</span> openai<span style="color:#f92672">.</span>ChatCompletion<span style="color:#f92672">.</span>create(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-4&#34;</span>,
</span></span><span style="display:flex;"><span>    messages<span style="color:#f92672">=</span>[
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: <span style="color:#e6db74">&#34;Expand only on these reasoning elements:&#34;</span>},
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: reasoning_response},
</span></span><span style="display:flex;"><span>    ],
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(api_response)
</span></span></code></pre></div><p>This approach optimally leverages local and remote AI resources.</p>
<p>‚ú® Wrap-Up</p>
<p>Whether you&rsquo;re prototyping, building products, or just experimenting, Ollama makes it simple and powerful.
If you build something cool, let me know‚ÄîI‚Äôd love to check it out!</p>

        </div>
    </div>
</div>

        </main>
        
<footer class="mt-32 text-center">
    <div class="max-w-3xl mx-auto">
        <div class="border-t border-gray-800 pt-5">
            <div class="flex flex-col items-center justify-center gap-4">                
                
                <div class="flex flex-wrap justify-center gap-4 mb-2">
                    <a href="mailto:mailto:nppedronp@gmail.com" class="animated-link text-gray-400 hover:text-gray-200">
                        <i class="fas fa-envelope mr-2"></i>Email
                    </a>
                    
                    <a href="https://github.com/PedroNunesPagnussat" target="_blank" class="animated-link text-gray-400 hover:text-gray-200">
                        <i class="fab fa-github mr-2"></i>GitHub
                    </a>
                    
                    
                    <a href="https://linkedin.com/in/pedronp" target="_blank" class="animated-link text-gray-400 hover:text-gray-200">
                        <i class="fab fa-linkedin mr-2"></i>LinkedIn
                    </a>
                    
                </div>
                
                <p class="text-gray-500 text-xm">¬© 2025 Pedro Nunes Pagnussat</p>
                <p class="text-gray-500 text-xm pb-12">Built using <a href="https://gohugo.io/" target="_blank" class="animated-link text-gray-400 hover:text-gray-200">Hugo</a>. & <a href="https://github.com/prxshetty/hugo-noir" target="_blank" class="animated-link text-gray-400 hover:text-gray-200">Hugo Noir</a></p>
            </div>
        </div>
    </div>
</footer>


<div id="go-to-top" title="Go to top">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <path d="M12 19V5M5 12l7-7 7 7"/>
    </svg>
</div>

<style>
#go-to-top {
    position: fixed;
    bottom: 30px;
    right: 30px;
    background-color: #333;
    color: white;
    width: 40px;
    height: 40px;
    border-radius: 50%;
    display: none;
    justify-content: center;
    align-items: center;
    cursor: pointer;
    transition: opacity 0.3s, visibility 0.3s;
    z-index: 1000;
    opacity: 0.7;
}

#go-to-top:hover {
    opacity: 1;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    var goToTop = document.getElementById('go-to-top');
    
    
    window.addEventListener('scroll', function() {
        if (window.pageYOffset > 100) {
            goToTop.style.display = 'flex';
        } else {
            goToTop.style.display = 'none';
        }
    });
    
    
    goToTop.addEventListener('click', function() {
        window.scrollTo({
            top: 0,
            behavior: 'smooth'
        });
    });
});
</script> 

<style>
    .animated-link {
        position: relative;
        display: inline-flex;
        align-items: center;
    }
    
    .animated-link::after {
        content: '';
        position: absolute;
        width: 0;
        height: 1px;
        bottom: -1px;
        left: 0;
        background-color: #ffffff;
        transition: width 0.3s ease-in-out;
    }
    
    .animated-link:hover::after {
        width: 100%;
    }
</style> 
    </body>
</html> 